# HIT-MHAD：A multimodal human action recognition dataset fabricated by using depth cameras and 24-dimensional wearable stretch sensors
# HIT_MHAD: 利用深度相机和24维可穿戴拉伸传感器制作的多模态人体动作识别数据集
In order to facilitate the research of multimodal sensor fusion for human motion recognition, this paper provides a multimodal human motion dataset using Kinect depth camera and wearable stretch sensor, called the Harbin Institute of Technology Multimodal Human Motion Dataset (HIT-MHAD). The dataset includes data from a 24-dimensional wearable stretch sensor and depth data from the Kinect. The HIT-MHAD dataset provides time-synchronized depth video, skeleton joint position, and tension sensor data.

为了便于多模态传感器融合用于人体动作识别的研究，本文提供了一个使用Kinect深度摄像头和可穿戴拉伸传感器的多模态人体动作数据集，称为哈尔滨工业大学多模态人体动作数据集（HIT-MHAD）。该数据集包含了来自24维可穿戴拉伸传感器的数据，和来自Kinect的深度数据。HIT-MHAD数据集提供了时间同步深度视频、骨架关节位置和拉伸传感器数据。
### 1.传感器
使用传感器包括kinect


和24维拉伸传感器
### 2.同步
不同模态的传感器之间通过时间戳进行同步
### 3.数据集介绍
HIT-MHAD采集了来自9位测试人员的数据，每位测试人员采集了27种动作，每个动作10次到15次，包括如下动作：
arm cross, arm curl, balling, baseball, boxing, catch, clap, draw O clockwise, draw O counter clockwise, draw triangle, draw x, jog,knock, lunge, pickup and throw, push, sit to stand, squat, stand to sit, swipe left, swipe right, tennis serve, tennis swing, throw, walk, wave.
